{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../data/omniglot.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1623, 20, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "data_dir = '.'\n",
    "\n",
    "def get_subdirs(a_dir):\n",
    "    return [os.path.join(a_dir, name) for name in os.listdir(a_dir)\n",
    "            if os.path.isdir(os.path.join(a_dir, name))]\n",
    "\n",
    "def load_and_save(save_file, size=None):\n",
    "    data = []\n",
    "    languages = get_subdirs(os.path.join('../data/omniglot'))\n",
    "    for language_num, language in enumerate(languages):\n",
    "        characters = get_subdirs(language)\n",
    "        characters.sort()\n",
    "        for character_num, character in enumerate(characters):\n",
    "            character_images = []\n",
    "            instances = os.listdir(character)\n",
    "            instances.sort()\n",
    "            print(language_num, len(characters))\n",
    "            for instance in instances:\n",
    "                im = Image.open(os.path.join(character, instance))\n",
    "                if size:\n",
    "                    im = im.resize((size, size), resample=Image.LANCZOS)\n",
    "                image = np.array(im.getdata()).astype('float32').reshape(size, size) / 255.\n",
    "                image = 1.0 - image  # invert the data as Omniglot is black on white\n",
    "\n",
    "                character_images.append((image, character_num, language_num))\n",
    "            data.append(character_images)\n",
    "    return np.array(data)\n",
    "#     np.save(save_file, np.array(data, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(data, augment_data):\n",
    "    images, char_nums = [], []\n",
    "    if augment_data:\n",
    "        for character in data:\n",
    "            data = augment_character_set(data, character)\n",
    "    for character_index, character in enumerate(data):\n",
    "        for m, instance in enumerate(character):\n",
    "#             print(instance)\n",
    "            images.append(instance[0])\n",
    "            char_nums.append(character_index)\n",
    "#     print(np.array(images).shape)\n",
    "#     images = np.expand_dims(np.array(images), 4)\n",
    "    images = np.array(images)\n",
    "    char_number = np.array(char_nums)\n",
    "    return images, char_number\n",
    "\n",
    "\n",
    "def augment_character_set(data, character_set):\n",
    "    \"\"\"\n",
    "    :param data: Dataset the character belongs to.\n",
    "    :param character_set: np array containing instances of a character.\n",
    "    :return: Original data with added character sets for all defined permutations of the current character.\n",
    "    \"\"\"\n",
    "    rotation_90, rotation_180, rotation_270 = [], [], []\n",
    "    for instance in character_set:\n",
    "        image, char_num, char_language_num = instance\n",
    "        rotation_90.append((np.rot90(image, k=1), char_num, char_language_num))\n",
    "        rotation_180.append((np.rot90(image, k=2), char_num, char_language_num))\n",
    "        rotation_270.append((np.rot90(image, k=3), char_num, char_language_num))\n",
    "    print(np.array(rotation_90).shape, np.array(rotation_180).shape, np.array(rotation_270).shape)\n",
    "    augmented_data = np.array([rotation_90, rotation_180, rotation_270])\n",
    "    return np.vstack((data, augmented_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = load_and_save(None, size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1623, 20, 3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3) (20, 3) (20, 3)\n",
      "(20, 3) (20, 3) (20, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-106-33be767fcb07>:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  print(np.array(rotation_90).shape, np.array(rotation_180).shape, np.array(rotation_270).shape)\n",
      "<ipython-input-106-33be767fcb07>:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  augmented_data = np.array([rotation_90, rotation_180, rotation_270])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(160,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_data(all_data[:2], True)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "data = tfds.load(\"omniglot\", split=\"train\", batch_size=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique(y=<tf.Tensor: shape=(30,), dtype=int64, numpy=\n",
       "array([27, 30, 17, 12, 15, 37, 43, 48, 32,  3,  2, 21, 25, 13, 14, 35, 26,\n",
       "       20,  0, 38,  4, 16, 41, 24, 11, 10, 31,  5, 45, 22])>, idx=<tf.Tensor: shape=(19280,), dtype=int32, numpy=array([ 0,  1,  2, ...,  1, 23, 28], dtype=int32)>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.unique(data['alphabet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.constant([1,2,3])\n",
    "features = np.zeros((3,2))\n",
    "class_mask = tf.equal(tf.argmax(input=labels, axis=1), 1)\n",
    "class_features = tf.boolean_mask(tensor=features, mask=class_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 3])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True, False,  True])>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = tf.constant([0,1,2,1])\n",
    "labels = tf.one_hot(labels, 3, axis=1)\n",
    "class_mask = tf.equal(tf.argmax(input=labels, axis=1), 1)\n",
    "class_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.]])>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.ones((4,2))\n",
    "tf.boolean_mask(tensor=features, mask=class_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.boolean_mask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
